"""LLM-powered semantic enrichment for tool schemas.

:class:`SchemaEnricher` uses an :class:`~aumai_llm_core.core.LLMClient` to
auto-detect capabilities, surface security implications, and identify PII
handling characteristics from a raw tool definition.  The result is a Pydantic-
validated :class:`EnrichmentResult` that can be fed directly into
:class:`~aumai_toolcanon.store.StoredTool` or merged into an existing
:class:`~aumai_toolcanon.models.CanonicalTool`.

Use :class:`~aumai_llm_core.providers.MockProvider` in tests to avoid network
calls::

    from aumai_llm_core import LLMClient, ModelConfig, MockProvider
    from aumai_llm_core.core import ProviderRegistry

    mock_json = json.dumps({
        "capabilities": ["read", "filesystem"],
        "security_tags": ["filesystem_access"],
        "pii_tags": [],
        "description_enhancement": "Reads a file from disk and returns its text content.",
        "confidence": 0.9,
    })
    config = ModelConfig(provider="mock", model_id="mock-model")
    enricher = SchemaEnricher(
        LLMClient(config, ...)  # provider is a MockProvider returning mock_json
    )
    result = await enricher.enrich(tool_def)
"""

from __future__ import annotations

import json
import logging
from typing import Any

from pydantic import BaseModel, Field

from aumai_llm_core import LLMClient, ModelConfig
from aumai_llm_core.core import ProviderRegistry
from aumai_llm_core.models import CompletionRequest, Message
from aumai_llm_core.providers import MockProvider
from aumai_llm_core.structured import ExtractionError, StructuredExtractor

logger = logging.getLogger(__name__)


# ---------------------------------------------------------------------------
# Enrichment output model
# ---------------------------------------------------------------------------


class EnrichmentResult(BaseModel):
    """Structured output from :class:`SchemaEnricher`.

    Attributes:
        capabilities: Semantic capability tokens detected from the tool definition
            (e.g. ``["read", "filesystem"]``).
        security_tags: Security-relevant tags inferred by the LLM
            (e.g. ``["filesystem_access", "network"]``).
        pii_tags: PII-handling tags inferred by the LLM
            (e.g. ``["processes_user_data"]``).
        description_enhancement: An improved, more precise description of what
            the tool does, generated by the LLM.
        confidence: LLM-estimated confidence score (0.0–1.0) for the enrichment.
    """

    capabilities: list[str] = Field(
        default_factory=list,
        description="Semantic capability tokens: read, write, search, call, etc.",
    )
    security_tags: list[str] = Field(
        default_factory=list,
        description="Security tags such as 'filesystem_access', 'network', 'privileged'.",
    )
    pii_tags: list[str] = Field(
        default_factory=list,
        description="PII handling tags: 'processes_user_data', 'stores_pii', etc.",
    )
    description_enhancement: str = Field(
        default="",
        description="An improved, more precise description of the tool.",
    )
    confidence: float = Field(
        default=0.0,
        ge=0.0,
        le=1.0,
        description="Confidence in the enrichment (0.0–1.0).",
    )


# ---------------------------------------------------------------------------
# SchemaEnricher
# ---------------------------------------------------------------------------

_ENRICHMENT_SYSTEM_PROMPT = """\
You are a tool-schema enrichment assistant for the AumAI agent infrastructure.

Given a raw tool definition (in JSON), analyse it and respond with a JSON
object containing the following fields:

- capabilities (array of strings): semantic capability tokens such as "read",
  "write", "search", "call", "create", "delete", "list", "fetch", "query",
  "execute" and domain tokens such as "filesystem", "web", "database", "code",
  "email", "api", "network".  Include up to 5 tokens total.

- security_tags (array of strings): security-relevant tags inferred from the
  tool's name, description, and parameters.  Examples:
  "filesystem_access", "network_access", "privileged", "read_only",
  "destructive", "requires_auth", "exposes_secrets".

- pii_tags (array of strings): PII handling tags inferred from the tool
  definition.  Examples: "processes_user_data", "stores_pii",
  "anonymizes_data", "transmits_pii", "no_pii".

- description_enhancement (string): a concise, accurate, and improved
  description of the tool in 1–3 sentences.

- confidence (number, 0.0–1.0): your confidence in the enrichment quality.

Respond ONLY with a valid JSON object matching this schema.  No prose.
"""


class SchemaEnricher:
    """LLM-powered enrichment of tool schema definitions.

    Uses :class:`~aumai_llm_core.core.LLMClient` and
    :class:`~aumai_llm_core.structured.StructuredExtractor` to:

    1. Build a structured prompt from the raw tool definition.
    2. Call the LLM to generate capability, security, and PII tags.
    3. Parse and validate the response into an :class:`EnrichmentResult`.

    Args:
        client: An :class:`~aumai_llm_core.core.LLMClient` instance.  Pass a
            client backed by :class:`~aumai_llm_core.providers.MockProvider`
            in tests to avoid network calls.

    Example::

        from aumai_llm_core import LLMClient, ModelConfig

        config = ModelConfig(provider="mock", model_id="mock-model")
        client = LLMClient(config)
        enricher = SchemaEnricher(client)
        result = await enricher.enrich({"name": "read_file", ...})
        print(result.capabilities)   # ["read", "filesystem"]
    """

    def __init__(self, client: LLMClient) -> None:
        self._client = client
        self._extractor = StructuredExtractor(client)

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------

    async def enrich(
        self,
        tool_def: dict[str, Any],
    ) -> EnrichmentResult:
        """Enrich a raw tool definition with LLM-generated semantic metadata.

        The tool definition is serialized to JSON and included verbatim in the
        user turn of the LLM prompt.  The system turn instructs the model to
        respond with an :class:`EnrichmentResult`-compatible JSON object.

        Args:
            tool_def: Raw tool definition dictionary (any supported format).

        Returns:
            An :class:`EnrichmentResult` with populated capability, security,
            and PII tags plus an enhanced description.

        Raises:
            EnrichmentError: If the LLM response cannot be parsed into a valid
                :class:`EnrichmentResult`.
        """
        tool_json_str = json.dumps(tool_def, indent=2, default=str)
        user_content = (
            f"Please analyse the following tool definition and return enrichment "
            f"metadata as JSON:\n\n```json\n{tool_json_str}\n```"
        )

        request = CompletionRequest(
            messages=[
                Message(role="system", content=_ENRICHMENT_SYSTEM_PROMPT),
                Message(role="user", content=user_content),
            ],
        )

        try:
            response = await self._client.complete(request)
            result = self._extractor.parse_response(
                response.content, EnrichmentResult
            )
        except ExtractionError as exc:
            logger.warning(
                "SchemaEnricher: could not parse LLM response — %s. "
                "Returning empty EnrichmentResult.",
                exc,
            )
            raise EnrichmentError(
                f"Failed to parse LLM enrichment response: {exc}",
                raw_response=str(exc),
            ) from exc
        except Exception as exc:
            logger.error(
                "SchemaEnricher: unexpected error during enrichment — %s",
                exc,
                exc_info=True,
            )
            raise EnrichmentError(
                f"Unexpected enrichment error: {exc}",
            ) from exc

        return result

    async def enrich_safe(
        self,
        tool_def: dict[str, Any],
    ) -> EnrichmentResult:
        """Enrich without raising — returns an empty :class:`EnrichmentResult` on failure.

        Convenience wrapper around :meth:`enrich` that swallows
        :class:`EnrichmentError` and returns a zero-confidence default result
        instead.

        Args:
            tool_def: Raw tool definition dictionary.

        Returns:
            An :class:`EnrichmentResult` (may be empty if enrichment failed).
        """
        try:
            return await self.enrich(tool_def)
        except EnrichmentError:
            return EnrichmentResult()

    # ------------------------------------------------------------------
    # Factory helpers
    # ------------------------------------------------------------------

    @classmethod
    def with_mock(
        cls,
        responses: list[str] | None = None,
    ) -> "SchemaEnricher":
        """Create a :class:`SchemaEnricher` backed by :class:`~aumai_llm_core.providers.MockProvider`.

        Useful in unit tests and offline environments.

        Args:
            responses: List of canned JSON response strings.  If ``None`` a
                single default empty-enrichment JSON object is used.

        Returns:
            A :class:`SchemaEnricher` backed by :class:`~aumai_llm_core.providers.MockProvider`.
        """
        if responses is None:
            default_response = json.dumps(
                EnrichmentResult().model_dump(mode="json")
            )
            responses = [default_response]

        # Register the mock provider if it is not already registered
        if "mock" not in ProviderRegistry.available():
            ProviderRegistry.register("mock", MockProvider)

        # Build a client that uses a MockProvider with the given responses
        config = ModelConfig(provider="mock", model_id="mock-model")
        # Swap in a mock provider instance with our custom responses
        client = LLMClient(config)
        client._provider = MockProvider(responses=responses)  # noqa: SLF001

        return cls(client)


# ---------------------------------------------------------------------------
# Exception
# ---------------------------------------------------------------------------


class EnrichmentError(Exception):
    """Raised when schema enrichment fails.

    Attributes:
        raw_response: The raw LLM response text that could not be parsed,
            or an empty string if the error occurred before a response was
            obtained.
    """

    def __init__(self, message: str, raw_response: str = "") -> None:
        super().__init__(message)
        self.raw_response = raw_response


__all__ = ["EnrichmentResult", "EnrichmentError", "SchemaEnricher"]
